{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHfmUwRqrIWa",
        "outputId": "034c7453-c27b-42b4-db73-70ecca13a484"
      },
      "outputs": [],
      "source": [
        "# pip install opencv-python\n",
        "# pip install face_recognition\n",
        "# pip install dlib\n",
        "# pip install pandas\n",
        "# pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RcwNwq3Or5Mp",
        "outputId": "469426af-859a-4563-d6f7-8f85fcfd120b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "import face_recognition\n",
        "import pickle\n",
        "import datetime\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1qbSx_1xsKpG",
        "outputId": "c0581791-8b47-4ff2-aed1-1a1a859fa51a"
      },
      "outputs": [],
      "source": [
        "# مسار قاعدة البيانات\n",
        "dataset_dir = './content'\n",
        "encodings_file = 'encodings.pickle'\n",
        "\n",
        "# قوائم لحفظ البيانات\n",
        "known_encodings = []\n",
        "known_names = []\n",
        "\n",
        "# قراءة الصور وتشفيرها\n",
        "for person_name in os.listdir(dataset_dir):\n",
        "    person_dir = os.path.join(dataset_dir, person_name)\n",
        "    if not os.path.isdir(person_dir):\n",
        "        continue\n",
        "    for image_name in os.listdir(person_dir):\n",
        "        image_path = os.path.join(person_dir, image_name)\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        try:\n",
        "            encodings = face_recognition.face_encodings(image)[0]\n",
        "        except IndexError:\n",
        "            print(f\"لم يتم العثور على وجه في الصورة {image_path}\")\n",
        "            continue\n",
        "        known_encodings.append(encodings)\n",
        "        known_names.append(person_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g6i2_3v-ty0l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "تم إنشاء قاعدة البيانات بنجاح!\n"
          ]
        }
      ],
      "source": [
        "# حفظ التشفيرات\n",
        "data = {\"encodings\": known_encodings, \"names\": known_names}\n",
        "with open(encodings_file, \"wb\") as f:\n",
        "    f.write(pickle.dumps(data))\n",
        "\n",
        "print(\"تم إنشاء قاعدة البيانات بنجاح!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zUV5DjuAt19r"
      },
      "outputs": [],
      "source": [
        "# تحميل التشفيرات المعروفة\n",
        "with open('encodings.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PKWmgXSWt7y1"
      },
      "outputs": [],
      "source": [
        "# الوصول إلى الكاميرا\n",
        "video_capture = cv2.VideoCapture(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oxyD-bSbt9-U"
      },
      "outputs": [],
      "source": [
        "# قائمة لتخزين الأسماء المكتشفة\n",
        "recognized_names = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DjE4BR6quBJ0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x102ce99b0>, array([[[188, 150, 166],\n        [194, 156, 171],\n        [191, 154, 169],\n        ...,\n        [201, 172, 190],\n        [198, 170, 187],\n        [194, 165, 183]],\n\n       [[186, 148, 163],\n        [191, 156, 170],\n        [191, 156, 170],\n        ...,\n        [202, 173, 191],\n        [202, 173, 191],\n        [197, 168, 186]],\n\n       [[193, 155, 170],\n        [193, 158, 173],\n        [190, 154, 169],\n        ...,\n        [198, 170, 187],\n        [202, 173, 191],\n        [202, 173, 191]],\n\n       ...,\n\n       [[ 40,  26,  31],\n        [ 47,  33,  38],\n        [ 38,  25,  30],\n        ...,\n        [166, 141, 146],\n        [156, 129, 135],\n        [156, 129, 135]],\n\n       [[ 30,  16,  22],\n        [ 44,  30,  36],\n        [ 36,  22,  27],\n        ...,\n        [157, 132, 137],\n        [159, 131, 137],\n        [156, 129, 135]],\n\n       [[ 26,  12,  17],\n        [ 24,  11,  16],\n        [ 34,  20,  25],\n        ...,\n        [142, 117, 122],\n        [161, 133, 139],\n        [161, 133, 139]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x107d6c9f0>, 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(rgb_frame)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# تشفير الوجوه\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (top, right, bottom, left), face_encoding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(face_locations, face_encodings):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# مقارنة الوجوه\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     matches \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mcompare_faces(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencodings\u001b[39m\u001b[38;5;124m\"\u001b[39m], face_encoding)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(\u001b[43mface_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
            "\u001b[0;31mTypeError\u001b[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: list[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: list[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x102ce99b0>, array([[[188, 150, 166],\n        [194, 156, 171],\n        [191, 154, 169],\n        ...,\n        [201, 172, 190],\n        [198, 170, 187],\n        [194, 165, 183]],\n\n       [[186, 148, 163],\n        [191, 156, 170],\n        [191, 156, 170],\n        ...,\n        [202, 173, 191],\n        [202, 173, 191],\n        [197, 168, 186]],\n\n       [[193, 155, 170],\n        [193, 158, 173],\n        [190, 154, 169],\n        ...,\n        [198, 170, 187],\n        [202, 173, 191],\n        [202, 173, 191]],\n\n       ...,\n\n       [[ 40,  26,  31],\n        [ 47,  33,  38],\n        [ 38,  25,  30],\n        ...,\n        [166, 141, 146],\n        [156, 129, 135],\n        [156, 129, 135]],\n\n       [[ 30,  16,  22],\n        [ 44,  30,  36],\n        [ 36,  22,  27],\n        ...,\n        [157, 132, 137],\n        [159, 131, 137],\n        [156, 129, 135]],\n\n       [[ 26,  12,  17],\n        [ 24,  11,  16],\n        [ 34,  20,  25],\n        ...,\n        [142, 117, 122],\n        [161, 133, 139],\n        [161, 133, 139]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x107d6c9f0>, 1"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # تحويل الصورة من BGR إلى RGB\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # اكتشاف مواقع الوجوه\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    # تشفير الوجوه\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "        # مقارنة الوجوه\n",
        "        matches = face_recognition.compare_faces(data[\"encodings\"], face_encoding)\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        # العثور على أقرب تطابق\n",
        "        face_distances = face_recognition.face_distance(data[\"encodings\"], face_encoding)\n",
        "        best_match_index = face_distances.argmin()\n",
        "\n",
        "        if matches[best_match_index]:\n",
        "            name = data[\"names\"][best_match_index]\n",
        "\n",
        "        # رسم مربع حول الوجه\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "        # كتابة الاسم\n",
        "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # تسجيل الوقت والاسم إذا لم يتم تسجيله من قبل\n",
        "        if name != \"Unknown\" and name not in recognized_names:\n",
        "            recognized_names.append(name)\n",
        "            time_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            print(f\"{name} وصل في {time_stamp}\")\n",
        "            # يمكنك هنا حفظ البيانات في قاعدة بيانات أو ملف\n",
        "\n",
        "    # عرض الفيديو\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    # الخروج عند الضغط على 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n",
        "\n",
        "# تحرير الموارد\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr29E1g2uLlt"
      },
      "outputs": [],
      "source": [
        "# تحميل التشفيرات المعروفة\n",
        "with open('encodings.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# الوصول إلى الكاميرا\n",
        "video_capture = cv2.VideoCapture(2)\n",
        "\n",
        "# إنشاء القاموس للتتبع\n",
        "trackers = {}\n",
        "tracker_id = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # اكتشاف مواقع الوجوه\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "        matches = face_recognition.compare_faces(data[\"encodings\"], face_encoding)\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        face_distances = face_recognition.face_distance(data[\"encodings\"], face_encoding)\n",
        "        best_match_index = face_distances.argmin()\n",
        "\n",
        "        if matches[best_match_index]:\n",
        "            name = data[\"names\"][best_match_index]\n",
        "\n",
        "        # إنشاء متتبع جديد\n",
        "        tracker = cv2.TrackerCSRT_create()\n",
        "        bbox = (left, top, right - left, bottom - top)\n",
        "        tracker.init(frame, bbox)\n",
        "        trackers[tracker_id] = {'tracker': tracker, 'name': name}\n",
        "        tracker_id += 1\n",
        "\n",
        "    # تحديث وتتبع الجميع\n",
        "    for tid in list(trackers.keys()):\n",
        "        success, bbox = trackers[tid]['tracker'].update(frame)\n",
        "        if success:\n",
        "            x, y, w, h = [int(v) for v in bbox]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, trackers[tid]['name'], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "        else:\n",
        "            # إذا فشل التتبع، نحذفه\n",
        "            del trackers[tid]\n",
        "\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "# إنشاء الاتصال بقاعدة البيانات\n",
        "conn = sqlite3.connect('employee_data.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "# إنشاء جدول\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS movements\n",
        "             (name TEXT, time TEXT, event TEXT)''')\n",
        "\n",
        "# عند تسجيل حدث\n",
        "def log_event(name, event):\n",
        "    time_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    c.execute(\"INSERT INTO movements VALUES (?, ?, ?)\", (name, time_stamp, event))\n",
        "    conn.commit()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "log_event('Ahmed', 'Entered')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
